---
layout: post
title: 딥러닝-컴퓨터 비전 | 4. Object Detection 성능 평가 Metric (IoU, NMS, mAP)
description: 인프런 '[개정판] 딥러닝 컴퓨터 비전 완벽 가이드' 강의를 수강하며 공부한 내용을 정리한 글입니다.
sitemap: false
---

Object Detection 성능 평가 Metric 

* this unordered seed list will be replaced by the toc
{:toc}

## IoU (Intersection over Union)

모델이 예측한 결과와 실측(Ground Truth) Box가 얼마나 정확하게 겹치는가를 나타내는 지표

![IoU](/assets/img/blog/IoU.png)

![IoU2](/assets/img/blog/IoU2.png)

Pascal VOC: 0.5, MS COCO: 0.5~0.95
{:.figure}

## NMS (Non Max Suppression)

- Object Detection 알고리즘은 Object 가 있을 만한 위치에 많은 Detection을 수행하는 경향이 강함. 

- NMS는 Detected 된 Object의 Bounding box중에 비슷한 위치에 있는 box를 제거하고 가장 적합한 box를 선택하는 기법

![NMS](/assets/img/blog/NMS.png)

> NMS 수행 로직
1. Detected 된 bounding box별로 특정 Confidence threshold 이하 bounding box는 먼저 제거(confidence score < 0.5)
2. 가장 높은 confidence score를 가진 box 순으로 내림차순 정렬하고아래 로직을 모든 box에 순차적으로 적용.
높은 confidence score를 가진 box와 겹치는 다른 box를 모두 조사하여 IOU가 특정 threshold 이상인 box를 모두 제거 (예:IOU Threshold > 0.4 )
3. 남아 있는 box만 선택

> Confidence score가 **`높을 수록`**, IOU Threshold가 **`낮을 수록`** 많은 Box가 제거됨.
{: .lead}

## mAP

- 실제 Object가 Detected된 재현율(Recall)의 변화에 따른 정밀도(Presion)의 값을 평균한 성능 수치

- 각각의 클래스에 대한 AP의 평균

![mAP](/assets/img/blog/mAP.png)

## 정밀도(Precision)과 재현율(Recall)

- 정밀도(Precision)

    - 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율 

    - Object Detection에서는 검출 알고리즘이 검출 예측한 결과가 실제 Object들과 얼마나 일치하는지를 나타내는 지표

- 재현율(Recall)

    - 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율

    - Object Detection에서는 검출 알고리즘이 실제 Object들을 빠뜨리지 않고 얼마나 정확히 검출 예측하는지를 나타내는 지표

![Confusion Matrix](/assets/img/blog/ConfusionMatrix.png)

오차 행렬
{:.figure}

|  **정밀도 (Precision)**                  |        **재현율 (Recall)**       |
|:-----------------:|:---------------:|
|      TP / (FP + TP)          |         TP / (FN + TP)           |
|:-----------------:|:---------------:|
| 상대적으로 중요: 암 진단, 금융사기                |     상대적으로 중요: 스팸 메일                     |
|:-----------------:|:---------------:|
| 정밀도 100% => 확실한 기준이 되는 경우만 Positive로 예측  |  재현율 100% =>모든 환자를 Positive로 예측  |
|:-----------------:|:---------------:|

## Confidence threshold

![Confidence threshold](/assets/img/blog/Confidencethreshold.png)

>**Confidence 임계값에 따라 정밀도와 재현율의 값이 변화됨**
{:.lead}

![Confidence threshold2](/assets/img/blog/Confidencethreshold2.png)

- 정밀도 재현율 트레이드 오프 Recall(Precision Recall Trade-off)
    - 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다.

- 정밀도 재현율 곡선(Precision-Recall Curve)
    - Recall 값의 변화에 따른(Confidence값을 조정하면서 얻어진) Precision 값을 나타낸 곡선

    - AP = 정밀도 재현율 곡선의 면적 값


## AP

- AP는 한 개 오브젝트에 대한 성능 수치
- mAp는 여러 오브젝트들의 AP를 평균한 값

![AP](/assets/img/blog/AP.png)

- 개별 11개(0.0 ~ 1.0 까지) Recall 포인트별로 최대 Precision의 평균 값을 구함

$$
\begin{align*}
& AP = \frac{1}{11}(mP(r=0) + mP(r=0.1) + ….. + mP(r=1)) \newline
& = \frac{1}{11}( 1.0 + 1.0 + 1.0 + 1.0 + 1.0 + 0.6 + 0.6 + 0.57 + 0.57 + 0.5 + 0.5 ) \newline
& = \frac{1}{11}( 5 \times 1.0 + 0.6 \times 2 + 0.57 \times 2 + 0.5 \times 2) \newline
& = 0.758
\end{align*}
$$

![COCO mAP](/assets/img/blog/COCOmAP.png)

>COCO Challenge에서의 mAP --> IoU thr 증가에 따라서 엄격해짐


![mAP example](/assets/img/blog/mAPex.png)

데이터 세트와 알고리즘 별 mAP 수치 예시
{:.figure}

## **출처** 

- [[개정판] 딥러닝 컴퓨터 비전 완벽 가이드](https://www.inflearn.com/course/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C)