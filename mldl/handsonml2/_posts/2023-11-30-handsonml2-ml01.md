---
layout: post
title: 1. 한눈에 보는 머신러닝
categories: 
  - mldl
  - handsonml2
description: 핸즈온 머신러닝 2판에서 공부했던 내용을 정리하는 부분입니다.
sitemap: false
---

모든 데이터 과학자가 알아야 할 머신러닝의 여러가지 기초 개념과 용어 정리

* this unordered seed list will be replaced by the toc
{:toc}

## 1.1 머신러닝이란?

- 일반적 정의: 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)
- 공학적 정의: 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상 → 컴퓨터 프로그램은 작업 T와 측정 P에 대해 경험 E로 학습
- ex) 스팸 필터
    - T: 스팸인지 구분하는 것
    - P: 정확도 등
    - E: 훈련 데이터
    

## 1.2 왜 머신러닝을 사용하는가?

- 데이터 마이닝: 머신러닝 기술을 적용하여 대용량의 데이터를 분석해서 패턴을 발견하는 것
- 기존 솔루션으로는 많은 작업 및 규칙이 필요한 문제: 하나의 머신러닝 모델이 코드를 간단하게 하고 전통적인 방법보다 더 잘 수행
- 전통적인 방법으로는 해결하기 힘든 복잡한 문제: 가장 뛰어난 머신러닝 기법으로 해결
- 유동적인 환경: 머신러닝 시스템은 새로운 데이터에 적응할 수 있다.
- 복잡한 문제와 대량의 데이터에서 통찰 얻기

## 1.3 머신러닝 시스템의 종류

- 1.3.1 지도학습과 비지도 학습

    - 머신러닝 시스템은 학습하는 동안의 감독 형태나 정보량에 따라 분류 가능
    - 지도 학습
        - 알고리즘에 주입하는 훈련 데이터에 레이블 포함
        - 속성: 데이터 타입(attribute) (ex) 주행거리), 특성(feature): 속성 + 값 (ex) 주행거리=15000)
        - k-최근접 이웃, 선형 회귀, 로지스틱 회귀, SVM, 결정 트리와 랜덤 포레스트, 신경망
    - 비지도 학습
        - 훈련 데이터에 레이블 X → 시스템이 아무런 도움 없이 학습
        - 군집, 이상치 탐지와 특이치 탐지, 시각화와 차원 축소, 연관 규칙 학습
    - 준지도 학습
        - 일부만 레이블된 데이터를 학습
        - 대부분 지도 학습 + 비지도 학습으로 이루어짐
        - ex) 심층 신뢰 신경망(DBN)은 제한된 볼츠만 머신(RBM)이라는 비지도 학습에 기초
    - 강화 학습
        - 매우 다른 종류의 알고리즘
        - 에이전트(학습 시스템), 보상, 벌점, 정책(최고의 보상을 위한 최상의 전략)
        - 과정
            1. 관찰
            2. 정책에 따라 행동 선택
            3. 행동 실행
            4. 보상 or 벌점 받음
            5. 정책 수정(학습 단계)
            6. 최적의 정책 찾을 때까지 반복
        - 보행 로봇, 알파고

- 1.3.2 배치 학습과 온라인 학습

    - 입력 데이터 스트림으로부터 점진적 학습 가능 여부에 따라 분류
    - 배치 학습
        - 시스템이 점진적으로 학습 불가능 → 가용 데이터 모두 학습 후 시스템에 적용 (오프라인 학습)
        - 새로운 데이터 학습 시 다시 훈련 후 새 시스템으로 교체 필요
        - 전체 데이터셋 사용해 훈련 시 많은 컴퓨팅 자원 필요
        - 자원이 제한된 시스템이 스스로 학습 시 심각한 문제 발생 → 점진적 학습 알고리즘이 낫다
    - 온라인 학습
        - 데이터 순차적으로 ‘미니 배치’ 라는 작은 묶음 단위로 주입하여 학습
        - 매 학습 단계 빠르고 비용이 적게 든다
        - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응하는 시스템에 적합
        - 외부 메모리 학습에 사용 가능
        - 외부 메모리 학습
            - 보통 오프라인에서 실행(온라인 학습 X → 점진적 학습)
            - 외부 메모리를 이용하여 전체 데이터의 일부를 읽어 전체 데이터에 적용될 때까지 학습
        - 학습률
            - 변화하는 데이터에 얼마나 빠르게 적응할 것인지 (온라인 학습 시 중요 파라미터)
            - 높은 학습률: 데이터에 빠르게 적응하지만, 예전 데이터 금방 잊어버림
            - 낮은 학습률: 더 느리게 학습하지만, 데이터의 잡음에 덜 민감
        - 가장 큰 문제점: 시스템에 나쁜 데이터 주입 시 성능이 점진적으로 감소
        - 시스템, 데이터 모니터링을 통해 방지해야함

- 1.3.3 사례 기반 학습과 모델 기반 학습

    - 어떻게 일반화 되는가에 따라 분류
    - 사례 기반 학습
        - 시스템이 훈련 데이터를 기억하는 방식으로 학습 → 유사도 측정으로 새로운 데이터와 학습한 샘플 비교
    - 모델 기반 학습
        - 샘플들로 모델을 만들어 예측에 사용하는 것
        - 과정
            - 데이터 분석 → 모델 선택
            - 훈련 데이터로 모델 훈련
            - 효용 함수, 비용 함수를 사용하여 성능 측정 → 최소화하는 파라미터 찾기
            - 새로운 데이터에 모델 적용해 예측 (추론)

## 1.4 머신러닝의 주요 도전 과제

- 1.4.1 충분하지 않은 양의 데이터

    - 대부분의 머신러닝이 잘 작동하기 위해서는 데이터가 많아야 한다

- 1.4.2 대표성 없는 훈련 데이터

    - 일반화하려는 사례들을 대표하는 훈련세트 사용이 매우 중요
    - 샘플이 작으면 ‘샘플링 잡음’, 샘플이 너무 크면 ‘샘플링 편향’이 발생

- 1.4.3 낮은 품질의 데이터

    - 훈련 데이터 이상치, 에러, 잡음으로 가득하여 훈련 데이터 정제는 필요하다.

- 1.4.4 관련 없는 특성

    - 훈련 데이터에 관련 있는 특성이 많고 관련 없는 특성이 적어야 한다.
    - 특성 공학
        - 특성 선택: 훈련에 가장 유용한 특성 선택
        - 특성 추출: 특성을 결합하여 더 유용한 특성 만듦 (ex) 차원 축소)
        - 새로운 데이터 수집해 새 특성 만듦

- 1.4.5 훈련 데이터 과대적합

    - 과대적합: 모델이 훈련 데이터에 너무 맞아 일반성이 떨어지는 것
    - 훈련 데이터의 잡음의 양에 비해 모델이 너무 복잡할 때 발생
    - 해결 방법
        - 파라미터 수 적은 모델 사용, 특성 수 줄임, 모델 제약하여 단순화
        - 훈련 데이터 많이 모음
        - 훈련 데이터의 잡음을 줄임
    - 규제: 모델 단순하게 하고 제약을 가하는 것
    - 데이터에 완벽히 맞추는 것과 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾는 것이 좋다.
    - 학습 동안 적용할 규제의 양은 하이퍼파라미터가 결정
    - 하이퍼파라미터
        - 학습 알고리즘의 파라미터
        - 학습 알고리즘의 영향 받지 않고, 훈련전에 미리 지정, 훈련하는 동안 상수로 남아있는다.
        - 하이퍼파라미터 튜닝은 머신러닝 시스템 구축에서 매우 중요한 과정

- 1.4.6 훈련 데이터 과소적합

    - 과대적합의 반대, 모델이 너무 단순해서 데이터의 내재된 구조 학습 못하는 경우
    - 해결 방법
        - 모델 파라미터가 더 많은 강력한 모델 사용
        - 학습 알고리즘에 더 좋은 특성 제공(특성 공학)
        - 모델의 제약을 줄임(규제 하이퍼파라미터 감소)
    

## 1.5 테스트와 검증

>- 훈련 데이터를 훈련 세트, 테스트 세트로 나눔 (일반적을 8:2, 데이터의 크기가 더 크면 테스트의 비율을 낮춰도 됨)
>- 일반화 오차(외부 샘플 오차): 새로운 샘플에 대한 오류 비율
>- 테스트 세트에서 모델을 평가함으로써 오차에 대한 추정 값 얻음 → 모델이 얼마나 잘 작동될지 알려줌
>- ex) 훈련 오차가 낮지만 일반화 오차가 높으면 모델이 과대적합 되어있다는 것

- 1.5.1 하이퍼파라미터 튜닝과 모델 선택

    - 일반화 오차가 적은 최적의 하이퍼 파라미터 찾아 적용했지만 실제 결과가 예상보다 좋지 않다.
    - 모델이 테스트 세트에 최적화되었기 때문이다.
    - 해결 방법
        - 홀드아웃 검증
            - 과정
                - 훈련 세트에서 검증 세트를 만들어 냄
                - 훈련 세트에서 다양한 하이퍼파라미터 값 가진 여러 모델 훈련
                - 검증 세트에서 가장 좋은 성능 내는 모델 선택
                - 이 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델 만듦
                - 마지막으로 테스트 세트에서 평가하여 일반화 오차 추정
            - 단점
                - 검증 세트가 너무 작거나 클 때, 모델 선택이 잘못 될 수 있다.
        - 교차 검증
            - 작은 검증 세트를 여러 개 사용하여 반복 수행
            - 장점
                - 모든 모델이 평가를 평균하여 더 정확한 성능을 측정할 수 있다.
            - 단점
                - 훈련 시간이 검증 세트의 수에 비례하여 증가
    - 데이터 불일치
        - 어떤 경우 쉽게 많은 양의 훈련 데이터를 얻을 수 있지만, 이 데이터가 실제 제품에 사용될 데이터를 완벽하게 대표하지 못할 수 있다.
        - 훈련 세트를 훈련- 개발 세트로 나누어 평가에 이용
            - 훈련-개발 세트로 나누고 훈련 세트에서만 모델 훈련
            - 훈련-개발 세트에서 평가
            - 검증 세트에서 나쁜 성능을 보이면 데이터 불일치에 의한 것
            - 훈련-개발 세트에서 나쁜 성능을 보이면 과대적합된 것
    - 공짜 점심 없음 이론
        - 데이터에 대해 어떤 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없다.
        - 데이터에 관해 타당한 가정을 하고 적절한 모델 몇가지만 평가
        - ex) 간단한 작업: 규제의 수준이 다양한 선형 모델을 평가, 복잡한 작업: 여러가지 신경망을 평가

## 출처

- 핸즈온 머신러닝 2판