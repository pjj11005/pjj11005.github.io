---
layout: post
title: KT AIVLE SCHOOL 5기 4주차 | 머신러닝(Machine learning)(2)
description: KT AIVLE SCHOOL 5기 4주차에 진행한 머신러닝(Machine learning) 강의 내용 정리 글입니다.
sitemap: false
---

* this unordered seed list will be replaced by the toc
{:toc}

## 1. K-Fold Cross Validation

### Random Split의 문제

- 새로운 데이터에 대한 모델의 성능을 예측 못한 상태로 최종 평가 수행 → 더욱 정교한 평가 절차가 필요

### 개념

- 모든 데이터가 **평가에 한 번, 학습에 k-1번 사용 (단 k ≥ 2)**
- K개의 분할에 대한 성능을 예측 → 평균과 표준편차 계산 → **일반화 성능**
- **학습 데이터로 K-Fold Cross Validation 진행해야 함 (중요)**
- 장점과 단점
    - 장점
        - 모든 데이터 학습과 평가에 사용 가능
        - 과소적합 문제 방지 가능, **좀 더 일반화된 모델** 만들 수 있음
    - 단점
        - **반복 횟수가 많아서** 모델 학습과 평가에 **많은 시간이 소요**됨

### 실습

```python
# 1. 환경 준비
# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, classification_report

# 2. 데이터 이해
# 데이터 살펴보기
data.head()
# 기술통계 확인
data.describe().T

# 3. 데이터 준비
# Target 확인
target = 'Outcome'
# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[:, target]
# 학습용, 평가용 데이터 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)
# 정규화
scaler = MinMaxScaler()
x_train_s = scaler.fit_transform(x_train)
x_test_s = scaler.transform(x_test)

# 4. 성능 예측
models = {'Decision Tree' : DecisionTreeClassifier(max_depth = 5, random_state=1),
              'KNN' : KNeighborsClassifier(),
              'Logistic Regression' : LogisticRegression()}

def cross_val_models_classification(models, cv = 10, scoring = 'accuracy'):
    result = {}
    for model_name, model in models.items():
        if model_name == 'KNN':
            cv_score = cross_val_score(model, x_train_s, y_train, cv = cv, scoring = scoring)
        else:
            cv_score = cross_val_score(model, x_train, y_train, cv = cv, scoring = scoring)

        print(model_name, cv_score)
        print('평균:', cv_score.mean())
        print('표준편차:', cv_score.std())
        print()

        result[model_name] = cv_score.mean()
    
    return result

result = cross_val_models_classification(models)

# 시각화
plt.figure(figsize = (5, 3))
plt.barh(y = list(result), width = result.values())
plt.show()

# 성능 평가

model = models['Decision Tree']
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

## 2. Hyperparameter 튜닝

### Hyperparameter

- 모델의 성능 향상을 위해 최선의 하이퍼파라미터 값을 찾는 **다양한 시도**를 해야 함
    - Grid Search, Random Search
- KNN : **k 값이 작을수록 복잡**, 거리 계산법에 따라 성능이 달라질 수 있음
- Decision Tree
    - max_depth : **작을수록 모델 단순**
    - min_samples_leaf, min_samples_split : **클수록 단순**

### Random Search, Grid Search

- Grid Search : 파라미터 값 범위 모두 탐색, Random Search : 파라미터 값 범위에서 몇 개 선택
- Grid Search: 내부적인 **K-Fold Cross Validation**을 위해 **cv** 값을 지정 → **실제 수행되는 횟수**: `파라미터 조합 수 x cv`
- Random Search : `n_iter`로 지정한 수행 횟수 만큼의 파라미터 조합 수 탐색
- **유용한 탐색 방법: Random Search로 넓은 범위를 탐색 후 최적의 파라미터 조합 주변을 Grid Search 로 탐색**
- 모델링 목표 : **적절한 예측력**을 위해 **적절한 복잡도**의 모델 완성


### 실습

```python
# 1.환경 준비
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import mean_absolute_error, r2_score

# 2. 데이터 이해
data.head()
data.describe()

# 3. 데이터 준비
target = 'medv'
x = data.drop(target, axis=1)
y = data.loc[:, target]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

# 4. 성능 예측
model_dt = DecisionTreeRegressor(random_state = 1)
cv_score = cross_val_score(model_dt, x_train, y_train , cv = 10, scoring = 'r2')
print(cv_score)
print(cv_score.mean())
print(cv_score.std())

# 5. 모델 튜닝
# 파라미터 선언
  # max_depth: 1~50
param = {'max_depth' : range(1, 51)}

# Random Search 선언
  # cv=5
  # n_iter=20
  # scoring='r2'
model = RandomizedSearchCV(model_dt,          # 기본 모델
                           param,            # 파라미터 범위
                           cv = 5,            # K-Fold 개수
                           n_iter = 20,      # 선택할 임의 파라미터 개수
                           scoring = 'r2')   # 평가 방법

## GridSearchCV 선언
# model = GridSearchCV(model_dt,          # 기본 모델
#                      param,            # 파라미터 범위
#                      cv = 5,            # K-Fold 개수
#                      scoring = 'r2')   # 평가 방법

# 학습하기
model.fit(x_train, y_train)

# 중요 정보 확인
print('=' * 80)
print(model.cv_results_['mean_test_score'])
print('-' * 80)
print('최적파라미터:', model.best_params_)
print('-' * 80)
print('최고성능:', model.best_score_)
print('=' * 80)

# 변수 중요도
plt.figure(figsize=(5, 5))
plt.barh(y=list(x), width=model.best_estimator_.feature_importances_)
plt.show()

# 6. 성능 평가
# 예측하기
y_pred = model.predict(x_test)
# 평가하기
print('MAE:', mean_absolute_error(y_test, y_pred))
print('R2-Score:', r2_score(y_test, y_pred))
```